import numpy as np
import pandas as pd
import multiprocessing as mp
from tqdm import tqdm


# 1. Generator PRNG
class PCG64Generator:
    def __init__(self):
        self.rng = np.random.default_rng()

    def random(self, size=1):
        return self.rng.uniform(size=size)

    def normal(self, mu=0, sigma=1, size=1):
        return self.rng.normal(loc=mu, scale=sigma, size=size)

    def lognormal(self, mean=0, sigma=1, size=1):
        return self.rng.lognormal(mean=mean, sigma=sigma, size=size)

    def chi_squared(self, df, size=1):
        return self.rng.chisquare(df=df, size=size)


# 2. Funkcja równoległa

def process_row(local_index, mu_mat_global, sigma_mat_global, data_paid_global, Ultimate_Param_ResRisk_global):
    rng = PCG64Generator()

    m_i = mu_mat_global[local_index, :]
    sigma_i = sigma_mat_global[local_index, :]
    data_paid_copy = np.copy(data_paid_global)

    mm, n_cols = data_paid_copy.shape
    n_dev = len(m_i)

    if n_cols < n_dev + 1:
        extra_cols = (n_dev + 1) - n_cols
        data_paid_copy = np.hstack((data_paid_copy, np.full((mm, extra_cols), np.nan)))

    for j in range(len(m_i)):
        max_ind_row = max(1, mm - j)
        for i in range(max_ind_row - 1, mm):
            VAR_i_j = sigma_i[j] / data_paid_copy[i, j]
            lmean = np.log((m_i[j]) ** 2 / np.sqrt((m_i[j]) ** 2 + VAR_i_j))
            lstdev = np.sqrt(np.log(1 + (VAR_i_j / (m_i[j]) ** 2)))
            CL_i_j = rng.lognormal(lmean, lstdev, size=1)[0]
            data_paid_copy[i, j + 1] = data_paid_copy[i, j] * CL_i_j

    u_i = data_paid_copy[:, -1]
    return np.sum(u_i) - Ultimate_Param_ResRisk_global


# 3. Losowanie parametrów

def random_stochastic_parameters(sigma_j, dev, sd, mm, nSimPart):
    rng = PCG64Generator()
    nDev = len(dev)

    mu_part = np.zeros((nSimPart, nDev))
    sig_part = np.zeros((nSimPart, nDev))

    for j in range(nDev):
        mu_part[:, j] = rng.normal(mu=dev[j], sigma=sd[j], size=nSimPart)
        df = max(1, mm - j - 1)
        chi_list = rng.chi_squared(df, size=nSimPart)
        sig_part[:, j] = (np.floor(chi_list) * sigma_j[j]) / df

    return mu_part, sig_part


# 4. Główna funkcja batchowana

def stochastic_triangle_forward_test_szybki_batched(
        data_paid,
        sigma_j, dev, sd,
        simTotal=100000,
        Ultimate_Param_ReservingRisk=0,
        result_file="results_batched.csv",
        main_seed=202260011,
        batch_size=10000
):
    np.random.seed(main_seed)
    mm = data_paid.shape[0]
    nBatches = int(np.ceil(simTotal / batch_size))
    num_cores = max(2, mp.cpu_count() - 1)

    results = np.zeros(simTotal)

    with mp.Pool(processes=num_cores) as pool, tqdm(total=simTotal, desc="Postęp symulacji") as pbar:
        sim_done = 0

        for b in range(nBatches):
            start_b = sim_done
            end_b = min(sim_done + batch_size, simTotal)
            current_batch_size = end_b - start_b

            np.random.seed(main_seed + b)

            mu_part, sigma_part = random_stochastic_parameters(sigma_j, dev, sd, mm, current_batch_size)

            args = [(i, mu_part, sigma_part, data_paid, Ultimate_Param_ReservingRisk) for i in
                    range(current_batch_size)]
            batch_out = pool.starmap(process_row, args)
            batch_res = np.array(batch_out)

            results[start_b:end_b] = batch_res
            pd.DataFrame(batch_res).to_csv(result_file, mode='a', header=False, index=False)

            sim_done = end_b
            pbar.update(current_batch_size)

    print(f"===> Wykonano łącznie {sim_done} symulacji w {nBatches} partiach.")
    return results


if __name__ == "__main__":
    import numpy as np
    import pandas as pd
    import multiprocessing as mp

    # Wczytywanie danych
    data_paid = pd.read_csv("data_input.csv", sep=";", decimal=",").iloc[:, 1:].values
    wsp = pd.read_csv("wsp_csv.csv", sep=";", decimal=",").values

    dev = wsp[0, :60].astype(float)
    sigma_j = wsp[1, :60].astype(float)
    sd = wsp[2, :60].astype(float)

    # Uruchamianie symulacji
    result = stochastic_triangle_forward_test_szybki_batched(
        data_paid=data_paid,
        sigma_j=sigma_j,
        dev=dev,
        sd=sd,
        simTotal=100000,
        Ultimate_Param_ReservingRisk=0,
        result_file="results_batched.csv",
        main_seed=202260011,
        batch_size=10000
    )

    # Analiza wyników
    results_cale = 1.1392 * (result - 4232149669)
    print("Median:", np.median(results_cale))
    for q in [0.995, 0.996, 0.997, 0.998, 0.999]:
        quant_val = np.quantile(results_cale, q)
        print(f"Quantile {q}: {quant_val}")
    print("Mean:", np.mean(results_cale))
    print("Difference (Quantile - Mean):", np.quantile(results_cale, 0.995) - np.mean(results_cale))
